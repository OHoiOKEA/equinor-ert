#!/usr/bin/env python3
import datetime
import json
import os.path
import sys

timestamp = str(datetime.datetime.now())

# File written from the mocked bsub command which provides us with the path to
# where the job actually runs and where we can find i.e the job_id and status
with open("job_paths") as job_paths_file:
    job_paths = job_paths_file.read().splitlines()

print("JOBID USER STAT QUEUE FROM_HOST EXEC_HOST JOB_NAME SUBMIT_TIME")
for line in job_paths:
    if not os.path.isfile(line + "/lsf_info.json"):
        continue

    # ERT has picked up the mocked response
    # from mock_bsub and written the id to file
    with open(line + "/lsf_info.json") as id_file:
        _id = json.load(id_file)["job_id"]

    """
    Statuses LSF can give us
    "PEND"
    "SSUSP"
    "PSUSP"
    "USUSP"
    "RUN"
    "EXIT"
    "ZOMBI"  /* The ZOMBI status does not seem to be available from the api. */
    "DONE"
    "PDONE"  /* Post-processor is done. */
    "UNKWN"
    """
    status = "RUN"
    if os.path.isfile(f"{line}/OK"):
        status = "DONE"

    # Together with the headerline this is actually how LSF is providing its statuses
    # on the job and how we are picking these up. In this mocked version i just check
    # if the job is done with the OK file and then print that status for the job_id
    # retrieved from the same runpath.
    print(
        f"{_id} pytest {status} normal mock_host mock_exec_host poly_0 {timestamp}"
    )

# Just to have a log for test purposes what is actually thrown towards the bjobs command
with open("bjobs_log", "a+") as f:
    f.write(f"{str(sys.argv)}\n")
