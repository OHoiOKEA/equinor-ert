pipeline {
    agent { label 'performance-test' }

    parameters {
        string(
            name: 'COMPARE_VERSION',
            defaultValue: '0001',
            description: 'The checked in baseline to compare against. Will also check against previous version to guard against large inadvertent fluctuations in the baseline.'
        )
        string(
            name: 'PYTEST_OPTIONS',
            defaultValue: '-sv  --runslow --benchmark-disable-gc',
            description: 'Optional parameters for pytest, eg. --benchmark-cprofile=tottime --benchmark-storage=file:///scratch/oompf/jenkins-ert-performance/.benchmarks'
        )
    }

    environment {
        BASE_DIR = '/scratch/oompf/jenkins-ert-performance/share_template'
    }

    stages {
        stage('install') {
            steps {
                sh """
                python3 -m venv env
                source env/bin/activate
                source /opt/rh/devtoolset-9/enable
                pip install --upgrade pip
                pip install .
                pip install -r dev-requirements.txt
                """
            }
        }
        stage('run benchmarks dark storage') {
            steps {
                sh """
                source env/bin/activate
                pytest tests/performance_tests/test_dark_storage_performance.py \
                  --benchmark-save=benchmark-dark-storage-jenkins \
                  --benchmark-compare=${COMPARE_VERSION} \
                  --benchmark-compare-fail=median:15% \
                  --benchmark-autosave \
                  --template-config-path=${env.BASE_DIR} \
                  --benchmark-min-rounds=25 \
                  --benchmark-sort=fullname \
                  --benchmark-warmup=on \
                  ${PYTEST_OPTIONS}
                """
            }
        }
        stage('run benchmarks enkf_fs') {
            steps {
                sh """
                source env/bin/activate
                pytest tests/performance_tests/enkf \
                  --benchmark-save=benchmark-enkf-fs-jenkins \
                  --benchmark-compare=${COMPARE_VERSION} \
                  --benchmark-compare-fail=median:50% \
                  --benchmark-autosave \
                  --template-config-path=${env.BASE_DIR} \
                  --benchmark-min-rounds=25 \
                  --benchmark-sort=fullname \
                  --benchmark-warmup=on \
                  ${PYTEST_OPTIONS}
                """
            }
        }
    }
    post {
        always {
            archiveArtifacts(
                artifacts: ".benchmarks/**"
            )
        }
    }
}
